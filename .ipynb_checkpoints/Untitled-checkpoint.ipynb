{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e1274b-5c30-462f-95f6-c598cfcbc662",
   "metadata": {},
   "source": [
    "# Proyecto: Generación Automática de Resúmenes e Imágenes usando IA\n",
    "\n",
    "## Resumen\n",
    "El objetivo de este proyecto es desarrollar un sistema que genere automáticamente **resúmenes de textos largos** y **imágenes a partir de descripciones textuales**.  \n",
    "Se utilizarán modelos preentrenados de Hugging Face: **BART** para los resúmenes y **Stable Diffusion** para la generación de imágenes.\n",
    "\n",
    "## Índice\n",
    "1. Introducción  \n",
    "2. Objetivos  \n",
    "3. Metodología  \n",
    "4. Herramientas y Tecnologías  \n",
    "5. Implementación  \n",
    "6. Resultados  \n",
    "7. Conclusiones  \n",
    "8. Referencias  \n",
    "\n",
    "## 1. Introducción\n",
    "El exceso de información dificulta extraer rápidamente las ideas principales de textos largos y detallados, mientras que crear imágenes a partir de ideas requiere habilidades de diseño que muchos usuarios no poseen.  \n",
    "Este proyecto aborda estas problemáticas ofreciendo una solución automatizada que permite:  \n",
    "- Generar resúmenes claros y concisos de cualquier texto largo.  \n",
    "- Crear imágenes a partir de descripciones textuales de manera rápida y accesible.  \n",
    "\n",
    "## 2. Objetivos\n",
    "1. Generar **resúmenes automáticos de textos largos** en distintos niveles de detalle.  \n",
    "2. Generar **imágenes a partir de descripciones textuales**.  \n",
    "3. Evaluar la calidad y fidelidad de los resultados generados por los modelos.  \n",
    "\n",
    "## 3. Metodología\n",
    "1. **Recopilación de datos:** Seleccionar textos extensos y descripciones para generar imágenes.  \n",
    "2. **Procesamiento de texto:**  \n",
    "   - Usar BART para generar resúmenes  \n",
    "3. **Generación de imágenes:**  \n",
    "   - Usar Stable Diffusion para crear imágenes a partir de descripciones textuales.  \n",
    "   - Refinar prompts para mejorar calidad y coherencia.  \n",
    "\n",
    "## 4. Herramientas y Tecnologías\n",
    "- **Python 3.11**  \n",
    "- **Jupyter Notebook / Google Colab**  \n",
    "- **Hugging Face Transformers:** `facebook/bart-large-cnn`  \n",
    "- **Hugging Face Diffusers:** `runwayml/stable-diffusion-v1-5`  \n",
    "- Librerías: `transformers`, `diffusers`, `torch`, `PIL`  \n",
    "\n",
    "## 5. Implementación\n",
    "\n",
    "### 5.1 Instalación de librerías\n",
    "```python\n",
    "!pip install transformers diffusers torch pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "264e0936-9f55-4fd4-aec2-d5f93a19ccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La inteligencia artificial ha transformado múltiples áreas de la vida cotidiana and profesional. Sin embargo, su impacto no está exento de desafíos. El sesgo en los algoritmos\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Crear un pipeline de resumen\n",
    "resumidor = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "texto = \"\"\"\n",
    "En los últimos años, la inteligencia artificial ha transformado múltiples áreas de la vida cotidiana y profesional.\n",
    "Desde asistentes virtuales que ayudan a las personas en sus tareas diarias, hasta algoritmos de recomendación en plataformas de streaming y comercio electrónico,\n",
    "la presencia de esta tecnología es cada vez más evidente. Sin embargo, su impacto no está exento de desafíos.\n",
    "\n",
    "Uno de los principales debates gira en torno a la ética en el uso de la inteligencia artificial.\n",
    "El sesgo en los algoritmos, la privacidad de los datos y la automatización del trabajo son preocupaciones recurrentes que requieren regulación y un desarrollo responsable.\n",
    "Mientras algunos expertos destacan el potencial de la IA para mejorar la productividad y la calidad de vida,\n",
    "otros advierten sobre los riesgos de una dependencia excesiva de sistemas automatizados.\n",
    "\n",
    "A futuro, se espera que la inteligencia artificial juegue un papel clave en la medicina,\n",
    "con diagnósticos más precisos y tratamientos personalizados, así como en la educación,\n",
    "con herramientas adaptativas que respondan a las necesidades específicas de cada estudiante.\n",
    "No obstante, el éxito de estas implementaciones dependerá de la capacidad de la sociedad para equilibrar innovación con responsabilidad,\n",
    "asegurando que los beneficios de la IA sean accesibles para todos.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Generar resumen\n",
    "resumen = resumidor(texto, max_length=60, min_length=20, do_sample=False)\n",
    "print(resumen[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed0e2286-a419-4813-a7db-a151b90e752c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diffusers\n",
      "  Downloading diffusers-0.35.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.56.1)\n",
      "Requirement already satisfied: torch in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.8.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.23.0-cp311-cp311-win_amd64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.8.0-cp311-cp311-win_amd64.whl.metadata (7.2 kB)\n",
      "Collecting pillow\n",
      "  Downloading pillow-11.3.0-cp311-cp311-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting importlib_metadata (from diffusers)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.34.0 in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers) (0.34.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers) (2.3.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers) (2025.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers) (0.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.34.0->diffusers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.34.0->diffusers) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting zipp>=3.20 (from importlib_metadata->diffusers)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->diffusers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->diffusers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->diffusers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\noxiepc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->diffusers) (2025.8.3)\n",
      "Downloading diffusers-0.35.1-py3-none-any.whl (4.1 MB)\n",
      "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 2.4/4.1 MB 12.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.9/4.1 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.1/4.1 MB 8.8 MB/s  0:00:00\n",
      "Downloading torchvision-0.23.0-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 10.7 MB/s  0:00:00\n",
      "Downloading torchaudio-2.8.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 2.4/2.5 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 11.0 MB/s  0:00:00\n",
      "Downloading pillow-11.3.0-cp311-cp311-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 2.4/7.0 MB 12.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.7/7.0 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/7.0 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 11.3 MB/s  0:00:00\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zipp, pillow, importlib_metadata, torchvision, torchaudio, diffusers\n",
      "\n",
      "   ------ --------------------------------- 1/6 [pillow]\n",
      "   ------ --------------------------------- 1/6 [pillow]\n",
      "   ------ --------------------------------- 1/6 [pillow]\n",
      "   ------ --------------------------------- 1/6 [pillow]\n",
      "   ------ --------------------------------- 1/6 [pillow]\n",
      "   ------ --------------------------------- 1/6 [pillow]\n",
      "   ------ --------------------------------- 1/6 [pillow]\n",
      "   ------------- -------------------------- 2/6 [importlib_metadata]\n",
      "   -------------------- ------------------- 3/6 [torchvision]\n",
      "   -------------------- ------------------- 3/6 [torchvision]\n",
      "   -------------------- ------------------- 3/6 [torchvision]\n",
      "   -------------------- ------------------- 3/6 [torchvision]\n",
      "   -------------------- ------------------- 3/6 [torchvision]\n",
      "   -------------------- ------------------- 3/6 [torchvision]\n",
      "   -------------------- ------------------- 3/6 [torchvision]\n",
      "   -------------------- ------------------- 3/6 [torchvision]\n",
      "   -------------------- ------------------- 3/6 [torchvision]\n",
      "   -------------------- ------------------- 3/6 [torchvision]\n",
      "   -------------------- ------------------- 3/6 [torchvision]\n",
      "   -------------------- ------------------- 3/6 [torchvision]\n",
      "   -------------------- ------------------- 3/6 [torchvision]\n",
      "   -------------------- ------------------- 3/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchaudio]\n",
      "   -------------------------- ------------- 4/6 [torchaudio]\n",
      "   -------------------------- ------------- 4/6 [torchaudio]\n",
      "   -------------------------- ------------- 4/6 [torchaudio]\n",
      "   -------------------------- ------------- 4/6 [torchaudio]\n",
      "   -------------------------- ------------- 4/6 [torchaudio]\n",
      "   -------------------------- ------------- 4/6 [torchaudio]\n",
      "   -------------------------- ------------- 4/6 [torchaudio]\n",
      "   -------------------------- ------------- 4/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   --------------------------------- ------ 5/6 [diffusers]\n",
      "   ---------------------------------------- 6/6 [diffusers]\n",
      "\n",
      "Successfully installed diffusers-0.35.1 importlib_metadata-8.7.0 pillow-11.3.0 torchaudio-2.8.0 torchvision-0.23.0 zipp-3.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script diffusers-cli.exe is installed in 'C:\\Users\\NoxiePC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers transformers torch torchvision torchaudio pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34b60bc1-ba65-4b6c-bb6b-6814dbdcd2b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9cef3024a74cd88bb2602c0acdf2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90806eee00424eabb9fa4dba74384be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x0000022D0376F880>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\NoxiePC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\std.py\", line 1147, in __del__\n",
      "    def __del__(self):\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m prompt = \u001b[33m\"\u001b[39m\u001b[33mUn gato astronauta explorando la luna en estilo anime\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Generar imagen\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m imagen = \u001b[43mmodelo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m.images[\u001b[32m0\u001b[39m]\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Mostrar y guardar imagen\u001b[39;00m\n\u001b[32m     24\u001b[39m imagen.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\diffusers\\pipelines\\stable_diffusion\\pipeline_stable_diffusion.py:1041\u001b[39m, in \u001b[36mStableDiffusionPipeline.__call__\u001b[39m\u001b[34m(self, prompt, height, width, num_inference_steps, timesteps, sigmas, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, ip_adapter_image, ip_adapter_image_embeds, output_type, return_dict, cross_attention_kwargs, guidance_rescale, clip_skip, callback_on_step_end, callback_on_step_end_tensor_inputs, **kwargs)\u001b[39m\n\u001b[32m   1038\u001b[39m     latent_model_input = \u001b[38;5;28mself\u001b[39m.scheduler.scale_model_input(latent_model_input, t)\n\u001b[32m   1040\u001b[39m \u001b[38;5;66;03m# predict the noise residual\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1041\u001b[39m noise_pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43munet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlatent_model_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimestep_cond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimestep_cond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[43m    \u001b[49m\u001b[43madded_cond_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43madded_cond_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m   1051\u001b[39m \u001b[38;5;66;03m# perform guidance\u001b[39;00m\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.do_classifier_free_guidance:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\diffusers\\models\\unets\\unet_2d_condition.py:1215\u001b[39m, in \u001b[36mUNet2DConditionModel.forward\u001b[39m\u001b[34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, added_cond_kwargs, down_block_additional_residuals, mid_block_additional_residual, down_intrablock_additional_residuals, encoder_attention_mask, return_dict)\u001b[39m\n\u001b[32m   1212\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_adapter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(down_intrablock_additional_residuals) > \u001b[32m0\u001b[39m:\n\u001b[32m   1213\u001b[39m         additional_residuals[\u001b[33m\"\u001b[39m\u001b[33madditional_residuals\u001b[39m\u001b[33m\"\u001b[39m] = down_intrablock_additional_residuals.pop(\u001b[32m0\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1215\u001b[39m     sample, res_samples = \u001b[43mdownsample_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemb\u001b[49m\u001b[43m=\u001b[49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43madditional_residuals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     sample, res_samples = downsample_block(hidden_states=sample, temb=emb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\diffusers\\models\\unets\\unet_2d_blocks.py:1269\u001b[39m, in \u001b[36mCrossAttnDownBlock2D.forward\u001b[39m\u001b[34m(self, hidden_states, temb, encoder_hidden_states, attention_mask, cross_attention_kwargs, encoder_attention_mask, additional_residuals)\u001b[39m\n\u001b[32m   1260\u001b[39m     hidden_states = attn(\n\u001b[32m   1261\u001b[39m         hidden_states,\n\u001b[32m   1262\u001b[39m         encoder_hidden_states=encoder_hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1266\u001b[39m         return_dict=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1267\u001b[39m     )[\u001b[32m0\u001b[39m]\n\u001b[32m   1268\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1269\u001b[39m     hidden_states = \u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1270\u001b[39m     hidden_states = attn(\n\u001b[32m   1271\u001b[39m         hidden_states,\n\u001b[32m   1272\u001b[39m         encoder_hidden_states=encoder_hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1276\u001b[39m         return_dict=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1277\u001b[39m     )[\u001b[32m0\u001b[39m]\n\u001b[32m   1279\u001b[39m \u001b[38;5;66;03m# apply additional residuals to the output of the last pair of resnet and attention blocks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\diffusers\\models\\resnet.py:366\u001b[39m, in \u001b[36mResnetBlock2D.forward\u001b[39m\u001b[34m(self, input_tensor, temb, *args, **kwargs)\u001b[39m\n\u001b[32m    363\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.nonlinearity(hidden_states)\n\u001b[32m    365\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.dropout(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.conv_shortcut \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    369\u001b[39m     input_tensor = \u001b[38;5;28mself\u001b[39m.conv_shortcut(input_tensor.contiguous())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Cargar modelo de difusión estable\n",
    "modelo = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Usar GPU si está disponible\n",
    "if torch.cuda.is_available():\n",
    "    modelo = modelo.to(\"cuda\")\n",
    "else:\n",
    "    modelo = modelo.to(\"cpu\")\n",
    "\n",
    "# Prompt de ejemplo\n",
    "prompt = \"Un gato astronauta explorando la luna en estilo anime\"\n",
    "\n",
    "# Generar imagen\n",
    "imagen = modelo(prompt).images[0]\n",
    "\n",
    "# Mostrar y guardar imagen\n",
    "imagen.show()\n",
    "imagen.save(\"gato_astronauta.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
